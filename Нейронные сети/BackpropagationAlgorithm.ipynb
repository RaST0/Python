{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gzip\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка данных\n",
    "data_sources = {\n",
    "    \"training_images\": \"train-images-idx3-ubyte.gz\", \n",
    "    \"test_images\": \"t10k-images-idx3-ubyte.gz\",  \n",
    "    \"training_labels\": \"train-labels-idx1-ubyte.gz\",  \n",
    "    \"test_labels\": \"t10k-labels-idx1-ubyte.gz\",}  \n",
    "data_dir = \"../_data\"\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "mnist_dataset = {}\n",
    "# Данные\n",
    "for key in (\"training_images\", \"test_images\"):\n",
    "    with gzip.open(os.path.join(data_dir, data_sources[key]), \"rb\") as mnist_file:\n",
    "        mnist_dataset[key] = np.frombuffer(\n",
    "            mnist_file.read(), np.uint8, offset=16\n",
    "        ).reshape(-1, 28 * 28)\n",
    "# Лейблы\n",
    "for key in (\"training_labels\", \"test_labels\"):\n",
    "    with gzip.open(os.path.join(data_dir, data_sources[key]), \"rb\") as mnist_file:\n",
    "        mnist_dataset[key] = np.frombuffer(mnist_file.read(), np.uint8, offset=8)\n",
    "\n",
    "x_train, y_train, x_test, y_test = (\n",
    "    mnist_dataset[\"training_images\"],\n",
    "    mnist_dataset[\"training_labels\"],\n",
    "    mnist_dataset[\"test_images\"],\n",
    "    mnist_dataset[\"test_labels\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подготовка данных\n",
    "training_sample, test_sample = 1000, 1000\n",
    "training_images = x_train[0:training_sample] / 255\n",
    "test_images = x_test[0:test_sample] / 255\n",
    "\n",
    "def one_hot_encoding(labels, dimension=10):\n",
    "    one_hot_labels = labels[..., None] == np.arange(dimension)[None]\n",
    "    return one_hot_labels.astype(np.float64)\n",
    "\n",
    "training_labels = one_hot_encoding(y_train[:training_sample])\n",
    "test_labels = one_hot_encoding(y_test[:test_sample])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функции активации\n",
    "def relu(x):\n",
    "    return (x >= 0) * x\n",
    "    \n",
    "def softmax(x):\n",
    "    expx = np.exp(x-x.max())\n",
    "    return expx / expx.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Иницализация параметров\n",
    "seed = 80112\n",
    "rng = np.random.default_rng(seed)\n",
    "learning_rate = 0.005 # Скорость обучения\n",
    "epochs = 5 # Количество эпох\n",
    "h = 100 # Длина скрытого слоя\n",
    "Ih=np.ones((1,h))\n",
    "pixels_per_image = 784\n",
    "num_labels = 10\n",
    "weights_1 = 0.2 * rng.random((pixels_per_image, h)) - 0.1\n",
    "weights_2 = 0.2 * rng.random((h, num_labels)) - 0.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Accuracy: 0.571\n",
      "Epoch: 1 Accuracy: 0.663\n",
      "Epoch: 2 Accuracy: 0.716\n",
      "Epoch: 3 Accuracy: 0.741\n",
      "Epoch: 4 Accuracy: 0.746\n"
     ]
    }
   ],
   "source": [
    "# Обучение сети\n",
    "for j in range(epochs):\n",
    "    for i in range(len(training_images)):\n",
    "        layer_0 = training_images[i]\n",
    "        layer_1 = np.dot(layer_0, weights_1)\n",
    "        layer_1 = relu(layer_1)\n",
    "        layer_2 = np.dot(layer_1, weights_2)\n",
    "        layer_2 = softmax(layer_2)\n",
    "        layer_2_delta = layer_2 - training_labels[i]\n",
    "        layer_2_gradient = np.dot(layer_1.reshape((h,1)),layer_2_delta.reshape((1,10))) \n",
    "        layer_1_delta = (layer_1*(Ih-layer_1))*np.dot(layer_2_delta,weights_2.T)\n",
    "        layer_1_gradient = delta2 = np.dot(training_images[i].reshape(784,1),layer_1_delta) \n",
    "        weights_1 -= learning_rate * layer_1_gradient\n",
    "        weights_2 -= learning_rate * layer_2_gradient\n",
    "    results_1 = relu(np.dot(test_images,weights_1))\n",
    "    results_2 = softmax(np.dot(results_1,weights_2))\n",
    "    test_accurate_predictions = np.sum(np.argmax(results_2, axis=1) == np.argmax(test_labels, axis=1))\n",
    "    print(\"Epoch: \"+ str(j)+ \" Accuracy: \"+ str(test_accurate_predictions / float(len(test_images))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "99ca3cc4135effd912ee8a920963f7ef1d1ced99b3c815bf7084eb301160236c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
